{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
    "import pyspark as ps\n",
    "import warnings\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just created a SparkContext\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # creating spark context\n",
    "    sc = ps.SparkContext('local[2]')\n",
    "    sqlContext = SQLContext(sc)\n",
    "    print(\"Just created a SparkContext\")\n",
    "except ValueError:\n",
    "    warnings.warn(\"SparkContext already exists in this scope\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('C:/Users/Suraj  kumar/Desktop/Forsk_Lab/Sentimental_Analysis/labeledTrainData.tsv',delimiter='\\t' )\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+\n",
      "|    id|sentiment|              review|\n",
      "+------+---------+--------------------+\n",
      "|5814_8|        1|With all this stu...|\n",
      "|2381_9|        1|\"The Classic War ...|\n",
      "|7759_3|        0|The film starts w...|\n",
      "|3630_4|        0|It must be assume...|\n",
      "|9495_8|        1|Superbly trashy a...|\n",
      "+------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              review|label|\n",
      "+--------------------+-----+\n",
      "|With all this stu...|    1|\n",
      "|\"The Classic War ...|    1|\n",
      "|The film starts w...|    0|\n",
      "|It must be assume...|    0|\n",
      "|Superbly trashy a...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df.select(\"review\",col(\"sentiment\").cast(\"Int\").alias(\"label\"))\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data rows: 19976 ; Testing data rows: 5024\n"
     ]
    }
   ],
   "source": [
    "dividedData = data.randomSplit([0.8, 0.2]) \n",
    "train_Data = dividedData[0] #index 0 = data training\n",
    "test_Data = dividedData[1] #index 1 = data testing\n",
    "train_rows = train_Data.count()\n",
    "test_rows = test_Data.count()\n",
    "print (\"Training data rows:\", train_rows, \"; Testing data rows:\", test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|              review|label|      SentimentWords|\n",
      "+--------------------+-----+--------------------+\n",
      "|\b\b\b\bA Turkish Bat...|    1|[\b\b\b\ba, turkish, ...|\n",
      "|!!!! POSSIBLE MIL...|    0|[!!!!, possible, ...|\n",
      "|!!!!! OF COURSE T...|    0|[!!!!!, of, cours...|\n",
      "|\" Så som i himmel...|    1|[\", så, som, i, h...|\n",
      "|\"54\" is a film ba...|    0|[\"54\", is, a, fil...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"SentimentWords\")\n",
    "tokenizedTrain = tokenizer.transform(train_Data)\n",
    "tokenizedTrain.show(5)\n",
    "type(tokenizedTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|              review|label|      SentimentWords|     MeaningfulWords|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "|\b\b\b\bA Turkish Bat...|    1|[\b\b\b\ba, turkish, ...|[\b\b\b\ba, turkish, ...|\n",
      "|!!!! POSSIBLE MIL...|    0|[!!!!, possible, ...|[!!!!, possible, ...|\n",
      "|!!!!! OF COURSE T...|    0|[!!!!!, of, cours...|[!!!!!, course, s...|\n",
      "|\" Så som i himmel...|    1|[\", så, som, i, h...|[\", så, som, himm...|\n",
      "|\"54\" is a film ba...|    0|[\"54\", is, a, fil...|[\"54\", film, base...|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#stopword remover\n",
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), \n",
    "                       outputCol=\"MeaningfulWords\")\n",
    "SwRemovedTrain = swr.transform(tokenizedTrain)\n",
    "SwRemovedTrain.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|     MeaningfulWords|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    1|[\b\b\b\ba, turkish, ...|(262144,[1536,232...|\n",
      "|    0|[!!!!, possible, ...|(262144,[571,1536...|\n",
      "|    0|[!!!!!, course, s...|(262144,[1536,559...|\n",
      "|    1|[\", så, som, himm...|(262144,[1998,208...|\n",
      "|    0|[\"54\", film, base...|(262144,[14,6286,...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Converting words feature into numerical feature.Austin Appleby's MurmurHash 3 algorithm\n",
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "numericTrainData = hashTF.transform(SwRemovedTrain).select(\n",
    "    'label', 'MeaningfulWords', 'features')\n",
    "numericTrainData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", \n",
    "                        maxIter=10, regParam=0.01)\n",
    "model = lr.fit(numericTrainData)\n",
    "print (\"Training is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|Label|     MeaningfulWords|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[!!!!!, possible,...|(262144,[991,1536...|\n",
      "|    0|[\"a, town, called...|(262144,[1294,199...|\n",
      "|    1|[\"a, little, nons...|(262144,[6500,718...|\n",
      "|    1|[\"a, truly, nice,...|(262144,[571,1492...|\n",
      "|    1|[\"addictive\", adj...|(262144,[14,571,6...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing data\n",
    "tokenizedTest = tokenizer.transform(test_Data)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTest).select(\n",
    "    'Label', 'MeaningfulWords', 'features')\n",
    "numericTest.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----+\n",
      "|     MeaningfulWords|prediction|Label|\n",
      "+--------------------+----------+-----+\n",
      "|[!!!!!, possible,...|       0.0|    0|\n",
      "|[\"a, town, called...|       0.0|    0|\n",
      "|[\"a, little, nons...|       1.0|    1|\n",
      "|[\"a, truly, nice,...|       1.0|    1|\n",
      "|[\"addictive\", adj...|       1.0|    1|\n",
      "+--------------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predicting testing data\n",
    "prediction = model.transform(numericTest)\n",
    "predictionFinal = prediction.select(\n",
    "    \"MeaningfulWords\", \"prediction\", \"Label\")\n",
    "predictionFinal.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct prediction: 4305 , total data: 5024 , accuracy: 0.8568869426751592\n"
     ]
    }
   ],
   "source": [
    "#accuracy score\n",
    "correctPrediction = predictionFinal.filter(\n",
    "    predictionFinal['prediction'] == predictionFinal['Label']).count()\n",
    "totalData = predictionFinal.count()\n",
    "print(\"correct prediction:\", correctPrediction, \", total data:\", totalData, \n",
    "      \", accuracy:\", correctPrediction/totalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|    review|\n",
      "+----------+\n",
      "|good movie|\n",
      "+----------+\n",
      "\n",
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(262144,[113432,1...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment=\"good movie\"\n",
    "from pyspark.sql.types import *\n",
    "cSchema = StructType([StructField(\"review\", StringType())]) \n",
    "test_list = [[comment]]\n",
    "new_data= sqlContext.createDataFrame(test_list,schema=cSchema)\n",
    "new_data.show()\n",
    "tokenizedTest = tokenizer.transform(new_data)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTest).select('features')\n",
    "numericTest.show()\n",
    "type(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       1.0|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.transform(numericTest)\n",
    "predictionFinal = prediction.select(\"prediction\")\n",
    "predictionFinal.show()\n",
    "type(predictionFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction\n",
       "0         1.0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionFinal.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
